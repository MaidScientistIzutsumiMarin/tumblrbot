from collections.abc import Sequence
from pathlib import Path
from typing import TYPE_CHECKING, Annotated, override

from openai.types import ChatModel
from pydantic import Field, NonNegativeFloat, NonNegativeInt, PositiveInt, Secret, StringConstraints
from pydantic_settings import BaseSettings, PydanticBaseSettingsSource, TomlConfigSettingsSource
from tomlkit import comment, table
from tomlkit.items import Table

if TYPE_CHECKING:
    from _typeshed import StrPath

# Having values validated as non-empty should make it easier for users to diagnose configuration issues.
NonEmptyString = Annotated[str, StringConstraints(strip_whitespace=True, min_length=1)]


class TOMLSettings(BaseSettings):
    @classmethod
    @override
    def settings_customise_sources(cls, settings_cls: type[BaseSettings], *args: object, **kwargs: object) -> tuple[PydanticBaseSettingsSource, ...]:
        return (TomlConfigSettingsSource(settings_cls),)

    def model_post_init(self, context: object) -> None:
        toml_files = self.model_config.get("toml_file")
        if isinstance(toml_files, (Path, str)):
            self.dump_toml(toml_files)
        elif isinstance(toml_files, Sequence):
            for toml_file in toml_files:
                self.dump_toml(toml_file)
        return super().model_post_init(context)

    def dump_toml(self, toml_file: "StrPath") -> None:
        toml_path = Path(toml_file)
        if not (toml_path.exists() and toml_path.stat().st_size > 0):
            toml_path.write_text(self.get_toml_table().as_string())

    def get_toml_table(self) -> Table:
        model_dump = self.model_dump(mode="json")
        toml_table = table()
        for name, value in self.__class__.model_fields.items():
            if value.description:
                for line in value.description.split(". "):
                    toml_table.add(comment(f"{line.removesuffix('.')}."))
            if isinstance(value.default, TOMLSettings):
                toml_table[name] = value.default.get_toml_table()
            else:
                toml_table[name] = model_dump[name]
        return toml_table


class Env(TOMLSettings, validate_default=False, toml_file="env.toml"):
    tumblr_consumer_key: NonEmptyString = Field("", description="Consumer key and secret for the Tumblr API that can be found by creating an app at https://tumblr.com/oauth/apps.")
    tumblr_consumer_secret: Secret[NonEmptyString] = Secret("")
    tumblr_oauth_token: NonEmptyString = Field("", description="Tumblr OAuth token and secret have to be generated by the user. We suggest you follow the instructions at the top of the README for https://github.com/tumblr/pytumblr")
    tumblr_oauth_secret: Secret[NonEmptyString] = Secret("")

    openai_api_key: Secret[NonEmptyString] = Field(Secret(""), description="OpenAI API key can be found at https://platform.openai.com/account/api-keys")
    openai_model: NonEmptyString = Field("", description="Model to use for the OpenAI API. This is the model that will be used to generate draft text. You need to first generate the training data for this model.")


class Settings(TOMLSettings, cli_parse_args=True, cli_avoid_json=True, cli_kebab_case=True, toml_file="config.toml"):
    class Generation(TOMLSettings):
        blogname: NonEmptyString = Field(
            "",
            description='The name of the blog which generated drafts will be uploaded to that appears in the URL. This must be a blog associated with the same account as the configured Tumblr secret values. Examples: "staff" for https://staff.tumblr.com and "changes" for https://tumblr.com/changes or https://tumblr.com/@changes',
            validate_default=False,
        )
        draft_count: NonNegativeInt = Field(150, description="The number of drafts to process. This will affect the number of tokens used with OpenAI. Setting to 0 will disable draft generation.")
        tags_chance: NonNegativeFloat = Field(0.1, description="The chance to generate tags for any given post. This will incur extra calls to OpenAI. Setting to 0 will disable tag generation. 0.1 is a 10% chance.")

    class Training(TOMLSettings):
        blognames: list[NonEmptyString] = Field(
            [],
            description='The names of the blogs which post data will be downloaded from that appears in the URL. This must be a blog associated with the same account as the configured Tumblr secret values. Examples: ["staff", "changes"] for https://staff.tumblr.com and https://www.tumblr.com/changes or https://www.tumblr.com/@changes',
            validate_default=False,
        )
        data_directory: Path = Field(Path("data"), description="Where to store downloaded post data.")
        output_file: Path = Field(Path("training.jsonl"), description="Where to output the training data that will be used to fine-tune the model.")
        target_epochs: PositiveInt = Field(3, description="The number of epochs fine-tuning will be run for.")
        max_output_tokens: PositiveInt = Field(32768, description="The max output tokens for the current model.")
        token_price: NonNegativeFloat = Field(1.50, description="The expected price in USD per million tokens during fine-tuning for the current model. Setting to 0 will treat fine-tuning as free.")

    user_message: str = Field("Write a comical Tumblr post.", description="The user message for the OpenAI API. This is the prompt that will be sent to the API to generate the text.")
    model_name: ChatModel = Field("gpt-4.1-nano", description="The name of the model that will be fine-tuned by the generated training data.")

    generation: Generation = Generation()  # pyright: ignore[reportCallIssue]
    training: Training = Training()  # pyright: ignore[reportCallIssue]


ENV = Env()  # pyright: ignore[reportCallIssue]
SETTINGS = Settings()  # pyright: ignore[reportCallIssue]
